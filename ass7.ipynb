{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtzkn2y2W5Vu",
        "outputId": "c59153c8-37d4-4b0c-fc65-b773e8c6f730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"The rapid advancement of technology has revolutionized various industries, including healthcare, finance, and education. With the proliferation of smartphones and internet connectivity, accessing information has become easier than ever before. However, this abundance of data presents new challenges for organizations seeking to extract valuable insights from unstructured text data.\"\n",
        "sentence2 = \"The abundance of data presents new challenges for organizations seeking to extract valuable insights from unstructured text data.\"\n",
        "sentence3 = \"Rapid advancement of technology has revolutionized various checking industries\""
      ],
      "metadata": {
        "id": "Dv6pU7_meRS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def Tokenise(sentence: str):\n",
        "    punctuation = string.punctuation + '[]{}()<>'\n",
        "    for char in punctuation:\n",
        "        sentence = sentence.replace(char, \" \")\n",
        "    sentence = sentence.lower()\n",
        "    tokens = sentence.split()\n",
        "    return tokens\n",
        "\n",
        "tokens = Tokenise(sentence1)\n",
        "tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMCvwizEeVUC",
        "outputId": "9fe1a78f-647e-4ce7-e10e-f7b5a0f6ca79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'rapid',\n",
              " 'advancement',\n",
              " 'of',\n",
              " 'technology',\n",
              " 'has',\n",
              " 'revolutionized',\n",
              " 'various',\n",
              " 'industries',\n",
              " 'including',\n",
              " 'healthcare',\n",
              " 'finance',\n",
              " 'and',\n",
              " 'education',\n",
              " 'with',\n",
              " 'the',\n",
              " 'proliferation',\n",
              " 'of',\n",
              " 'smartphones',\n",
              " 'and',\n",
              " 'internet',\n",
              " 'connectivity',\n",
              " 'accessing',\n",
              " 'information',\n",
              " 'has',\n",
              " 'become',\n",
              " 'easier',\n",
              " 'than',\n",
              " 'ever',\n",
              " 'before',\n",
              " 'however',\n",
              " 'this',\n",
              " 'abundance',\n",
              " 'of',\n",
              " 'data',\n",
              " 'presents',\n",
              " 'new',\n",
              " 'challenges',\n",
              " 'for',\n",
              " 'organizations',\n",
              " 'seeking',\n",
              " 'to',\n",
              " 'extract',\n",
              " 'valuable',\n",
              " 'insights',\n",
              " 'from',\n",
              " 'unstructured',\n",
              " 'text',\n",
              " 'data']"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RemoveStopWords(token):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_sentence=[word for word in token if not word in stop_words]\n",
        "  return filtered_sentence\n",
        "\n",
        "tokens = RemoveStopWords(tokens)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jdyca_Xf6c8",
        "outputId": "1c9a92e2-ff6c-43ba-a6e5-b5d701e9558e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rapid',\n",
              " 'advancement',\n",
              " 'technology',\n",
              " 'revolutionized',\n",
              " 'various',\n",
              " 'industries',\n",
              " 'including',\n",
              " 'healthcare',\n",
              " 'finance',\n",
              " 'education',\n",
              " 'proliferation',\n",
              " 'smartphones',\n",
              " 'internet',\n",
              " 'connectivity',\n",
              " 'accessing',\n",
              " 'information',\n",
              " 'become',\n",
              " 'easier',\n",
              " 'ever',\n",
              " 'however',\n",
              " 'abundance',\n",
              " 'data',\n",
              " 'presents',\n",
              " 'new',\n",
              " 'challenges',\n",
              " 'organizations',\n",
              " 'seeking',\n",
              " 'extract',\n",
              " 'valuable',\n",
              " 'insights',\n",
              " 'unstructured',\n",
              " 'text',\n",
              " 'data']"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos_tag_list = pos_tag(tokens)\n",
        "pos_tag_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R78D9JOfj_eE",
        "outputId": "5c696492-3450-41ee-9485-4f15fd4bf5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rapid', 'JJ'),\n",
              " ('advancement', 'NN'),\n",
              " ('technology', 'NN'),\n",
              " ('revolutionized', 'VBN'),\n",
              " ('various', 'JJ'),\n",
              " ('industries', 'NNS'),\n",
              " ('including', 'VBG'),\n",
              " ('healthcare', 'NN'),\n",
              " ('finance', 'NN'),\n",
              " ('education', 'NN'),\n",
              " ('proliferation', 'NN'),\n",
              " ('smartphones', 'NNS'),\n",
              " ('internet', 'VBP'),\n",
              " ('connectivity', 'NN'),\n",
              " ('accessing', 'VBG'),\n",
              " ('information', 'NN'),\n",
              " ('become', 'NN'),\n",
              " ('easier', 'NN'),\n",
              " ('ever', 'RB'),\n",
              " ('however', 'RB'),\n",
              " ('abundance', 'NN'),\n",
              " ('data', 'NNS'),\n",
              " ('presents', 'NNS'),\n",
              " ('new', 'JJ'),\n",
              " ('challenges', 'NNS'),\n",
              " ('organizations', 'NNS'),\n",
              " ('seeking', 'VBG'),\n",
              " ('extract', 'NN'),\n",
              " ('valuable', 'JJ'),\n",
              " ('insights', 'NNS'),\n",
              " ('unstructured', 'VBD'),\n",
              " ('text', 'NN'),\n",
              " ('data', 'NNS')]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stemming - Stemming is the process of reducing words to their root or base form by removing affixes (e.g., prefixes, suffixes).\n",
        "The goal of stemming is to reduce words to their common base or root form, which helps in information retrieval and text analysis.\n",
        "Stemming is a process that stems or removes last few characters from a word, often leading to incorrect meanings and spelling.\n",
        "\"\"\"\n",
        "porter = PorterStemmer()\n",
        "stemWords = [porter.stem(word) for word in tokens]\n",
        "stemWords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c57NJzBEkwKW",
        "outputId": "725d3287-2ba8-4b9e-e2a7-f77e39b35e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rapid',\n",
              " 'advanc',\n",
              " 'technolog',\n",
              " 'revolution',\n",
              " 'variou',\n",
              " 'industri',\n",
              " 'includ',\n",
              " 'healthcar',\n",
              " 'financ',\n",
              " 'educ',\n",
              " 'prolifer',\n",
              " 'smartphon',\n",
              " 'internet',\n",
              " 'connect',\n",
              " 'access',\n",
              " 'inform',\n",
              " 'becom',\n",
              " 'easier',\n",
              " 'ever',\n",
              " 'howev',\n",
              " 'abund',\n",
              " 'data',\n",
              " 'present',\n",
              " 'new',\n",
              " 'challeng',\n",
              " 'organ',\n",
              " 'seek',\n",
              " 'extract',\n",
              " 'valuabl',\n",
              " 'insight',\n",
              " 'unstructur',\n",
              " 'text',\n",
              " 'data']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lemmatization - Lemmatization is similar to stemming but involves reducing words to their base or dictionary form (lemma)\n",
        "using a vocabulary and morphological analysis of the words. Lemmatization ensures that the resulting word is a valid word.\n",
        "Lemmatization considers the context and converts the word to its meaningful base form, which is called Lemma.\n",
        "\"\"\"\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizeWord = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "lemmatizeWord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA67j5hhlnuY",
        "outputId": "f88aaa31-2f68-4768-a27d-48c742abb040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rapid',\n",
              " 'advancement',\n",
              " 'technology',\n",
              " 'revolutionized',\n",
              " 'various',\n",
              " 'industry',\n",
              " 'including',\n",
              " 'healthcare',\n",
              " 'finance',\n",
              " 'education',\n",
              " 'proliferation',\n",
              " 'smartphones',\n",
              " 'internet',\n",
              " 'connectivity',\n",
              " 'accessing',\n",
              " 'information',\n",
              " 'become',\n",
              " 'easier',\n",
              " 'ever',\n",
              " 'however',\n",
              " 'abundance',\n",
              " 'data',\n",
              " 'present',\n",
              " 'new',\n",
              " 'challenge',\n",
              " 'organization',\n",
              " 'seeking',\n",
              " 'extract',\n",
              " 'valuable',\n",
              " 'insight',\n",
              " 'unstructured',\n",
              " 'text',\n",
              " 'data']"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = open('doc1.txt')\n",
        "str1 = doc1.read()\n",
        "str1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GWd1J7lvm7GW",
        "outputId": "dacffcc2-ce47-46fb-aa87-6ac7010d8ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hi hello hi jo hello Niraj karanda sumit hey what are you doing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Term Frequency - Measures how frequently a term appears in a document. TF measures the frequency of a term (word) in a\n",
        "document relative to the total number of words in that document.\n",
        "TF = (freq of term in a doc / total number of terms in doc)\n",
        "\"\"\"\n",
        "tokens = Tokenise(str1)\n",
        "tf1 = {}\n",
        "for token in set(tokens):\n",
        "    tf1[token] = tokens.count(token)/len(tokens)\n",
        "tf1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVN3d_MNsZPJ",
        "outputId": "16a6b1c2-f70e-4cea-b9e4-9634eec20642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sumit': 0.07692307692307693,\n",
              " 'hey': 0.07692307692307693,\n",
              " 'are': 0.07692307692307693,\n",
              " 'niraj': 0.07692307692307693,\n",
              " 'hi': 0.15384615384615385,\n",
              " 'you': 0.07692307692307693,\n",
              " 'jo': 0.07692307692307693,\n",
              " 'what': 0.07692307692307693,\n",
              " 'karanda': 0.07692307692307693,\n",
              " 'doing': 0.07692307692307693,\n",
              " 'hello': 0.15384615384615385}"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = open('doc2.txt')\n",
        "str2 = doc2.read()\n",
        "str2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tmjwDBnhtSXg",
        "outputId": "2c2e94dd-272b-4964-a7a2-31a465d89b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what are you doing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Inverse Document Frequency - IDF measures the rarity of a term across all documents in the corpus.\n",
        "IDF = log(totalno of docs / no of docs containing the term + 1)\n",
        "\n",
        "TF-IDF combines TF and IDF to assign a weight to each term in a document relative to its importance in the entire corpus.\n",
        "\"\"\"\n",
        "tokens1 = Tokenise(str1)\n",
        "tokens2 = Tokenise(str2)\n",
        "docs = [tokens1,tokens2]\n",
        "tf_idf = {}\n",
        "for token in set(tokens1+tokens2):\n",
        "    cnt = 0\n",
        "    for tokens in docs:\n",
        "        if token in tokens:\n",
        "            cnt+=1\n",
        "    tf_idf[token] = np.log(2/cnt+1)\n",
        "tf_idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w4XWgZctcGe",
        "outputId": "664b7f98-6904-4663-a506-ed26cb228d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sumit': 1.0986122886681098,\n",
              " 'hey': 1.0986122886681098,\n",
              " 'are': 0.6931471805599453,\n",
              " 'niraj': 1.0986122886681098,\n",
              " 'hi': 1.0986122886681098,\n",
              " 'you': 0.6931471805599453,\n",
              " 'jo': 1.0986122886681098,\n",
              " 'what': 0.6931471805599453,\n",
              " 'karanda': 1.0986122886681098,\n",
              " 'doing': 0.6931471805599453,\n",
              " 'hello': 1.0986122886681098}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    }
  ]
}